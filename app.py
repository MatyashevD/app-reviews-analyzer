import datetime
import re
import spacy
import pandas as pd
import streamlit as st
import requests
from bs4 import BeautifulSoap
from google_play_scraper import reviews as gp_reviews, Sort
from app_store_scraper import AppStore
from collections import Counter, defaultdict
from transformers import pipeline

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NLP –º–æ–¥–µ–ª–∏
def load_nlp_model():
    try:
        return spacy.load("ru_core_news_sm")
    except:
        spacy.cli.download("ru_core_news_sm")
        return spacy.load("ru_core_news_sm")

nlp = load_nlp_model()

@st.cache_resource(show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏...")
def load_sentiment_model():
    return pipeline(
        "text-classification", 
        model="cointegrated/rubert-tiny-sentiment-balanced",
        framework="pt",
        device=-1
    )

def extract_google_play_id(url: str) -> str:
    match = re.search(r'id=([a-zA-Z0-9._-]+)', url)
    return match.group(1) if match else None

def extract_app_store_id(url: str) -> str:
    match = re.search(r'/id(\d+)', url)
    return match.group(1) if match else None

def get_app_store_rating(app_id: str) -> float:
    try:
        url = f"https://itunes.apple.com/ru/lookup?id={app_id}"
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        })
        data = response.json()
        return float(data['results'][0]['averageUserRating']) if data.get('results') else 0.0
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ App Store: {str(e)}")
        return 0.0

def get_google_play_reviews(app_url: str, lang: str = 'ru', country: str = 'ru', count: int = 100) -> tuple:
    app_id = extract_google_play_id(app_url)
    if not app_id:
        return [], 0.0
    
    try:
        from google_play_scraper import app
        app_info = app(app_id, lang=lang, country=country)
        rating = app_info.get('score', 0.0)
        
        result, _ = gp_reviews(
            app_id,
            lang=lang,
            country=country,
            count=count,
            sort=Sort.NEWEST
        )
        return [(r['at'], r['content'], 'Google Play', r['score']) for r in result], rating
    except:
        return [], 0.0

def get_app_store_reviews(app_url: str, country: str = 'ru', count: int = 100) -> tuple:
    app_id = extract_app_store_id(app_url)
    if not app_id:
        return [], 0.0
    
    try:
        rating = get_app_store_rating(app_id)
        
        app_name_match = re.search(r'/app/([^/]+)/', app_url)
        app_name = app_name_match.group(1) if app_name_match else "unknown_app"
        
        app = AppStore(country=country, app_id=app_id, app_name=app_name)
        app.review(how_many=count)
        
        return [(r['date'], r['review'], 'App Store', r['rating']) for r in app.reviews], rating
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ App Store: {str(e)}")
        return [], 0.0

def filter_reviews_by_date(reviews: list, start_date: datetime.datetime, end_date: datetime.datetime) -> list:
    return [r for r in reviews if start_date <= r[0] <= end_date]

def analyze_sentiments(reviews: list) -> list:
    try:
        sentiment_analyzer = load_sentiment_model()
        return [sentiment_analyzer(text[:512], truncation=True)[0] for _, text, _, _ in reviews]
    except:
        return [{'label': 'neutral', 'score': 0.5} for _ in reviews]

def extract_key_phrases(text: str) -> list:
    try:
        doc = nlp(text)
        phrases = []
        current_phrase = []
        
        for token in doc:
            if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'VERB']:
                current_phrase.append(token.text)
                if len(current_phrase) == 4:
                    phrases.append(' '.join(current_phrase))
                    current_phrase = []
            else:
                if current_phrase:
                    phrases.append(' '.join(current_phrase))
                    current_phrase = []
        
        if current_phrase:
            phrases.append(' '.join(current_phrase))
        
        filtered_phrases = [
            phrase for phrase in phrases 
            if 2 <= len(phrase.split()) <= 4
            and not any(c in phrase for c in ['@', '#', 'http'])
        ]
        
        return list(set(filtered_phrases))
    
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
        return []

def analyze_reviews(reviews: list) -> dict:
    analysis = {
        'sentiments': [],
        'key_phrases': Counter(),
        'platform_counts': Counter(),
        'examples': defaultdict(list),
        'gp_rating': 0.0,
        'ios_rating': 0.0
    }
    
    sentiments = analyze_sentiments(reviews)
    
    for idx, (date, text, platform, rating) in enumerate(reviews):
        analysis['sentiments'].append(sentiments[idx])
        analysis['platform_counts'][platform] += 1
        
        phrases = extract_key_phrases(text)
        for phrase in phrases:
            analysis['key_phrases'][phrase] += 1
            if len(analysis['examples'][phrase]) < 3:
                analysis['examples'][phrase].append(text[:150] + '...')
    
    return analysis

def display_analysis(analysis: dict, filtered_reviews: list):
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    st.session_state.analysis_data = analysis
    st.session_state.filtered_reviews = filtered_reviews
    
    tab1, tab2 = st.tabs(["–ê–Ω–∞–ª–∏—Ç–∏–∫–∞", "–í—Å–µ –æ—Ç–∑—ã–≤—ã"])
    
    with tab1:
        cols = st.columns(3)
        cols[0].metric("–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤", len(filtered_reviews))
        cols[1].metric(
            "Google Play", 
            f"{analysis['platform_counts']['Google Play']} –æ—Ç–∑—ã–≤–æ–≤",
            f"‚òÖ {analysis['gp_rating']:.1f}" if analysis['gp_rating'] > 0 else ""
        )
        cols[2].metric(
            "App Store", 
            f"{analysis['platform_counts']['App Store']} –æ—Ç–∑—ã–≤–æ–≤",
            f"‚òÖ {analysis['ios_rating']:.1f}" if analysis['ios_rating'] > 0 else ""
        )
        
        st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        sentiment_counts = {
            '–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ': sum(1 for s in analysis['sentiments'] if s['label'].lower() == 'positive'),
            '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ': sum(1 for s in analysis['sentiments'] if s['label'].lower() == 'neutral'),
            '–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ': sum(1 for s in analysis['sentiments'] if s['label'].lower() == 'negative')
        }

        if sum(sentiment_counts.values()) > 0:
            sentiment_df = pd.DataFrame.from_dict(sentiment_counts, orient='index', columns=['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
            st.bar_chart(sentiment_df)
        else:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        
        st.subheader("üîë –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã (–¢–æ–ø-15)")
        if analysis['key_phrases']:
            top_phrases = analysis['key_phrases'].most_common(15)
            
            st.markdown("""
            <style>
                .phrase-box {
                    border: 1px solid #e6e6e6;
                    border-radius: 8px;
                    padding: 15px;
                    margin: 10px 0;
                    background: #f9f9f9;
                }
                .phrase-text {
                    font-weight: 600;
                    color: #2c3e50;
                    font-size: 16px;
                }
                .phrase-count {
                    color: #3498db;
                    font-size: 14px;
                }
                .phrase-example {
                    color: #7f8c8d;
                    font-size: 14px;
                    margin-top: 8px;
                }
            </style>
            """, unsafe_allow_html=True)
            
            for phrase, count in top_phrases:
                examples = analysis['examples'].get(phrase, [])[:2]
                examples_html = "<br>".join([f"‚Ä¢ {ex}" for ex in examples])
                
                st.markdown(f"""
                <div class="phrase-box">
                    <div class="phrase-text">
                        {phrase} 
                        <span class="phrase-count">({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)</span>
                    </div>
                    <div class="phrase-example">
                        –ü—Ä–∏–º–µ—Ä—ã:<br>
                        {examples_html if examples else "–ù–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤"}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
    
    with tab2:
        st.subheader("üìã –í—Å–µ –æ—Ç–∑—ã–≤—ã")
        sentiment_translation = {
            'positive': '–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π',
            'neutral': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π',
            'negative': '–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π'
        }
        
        reviews_df = pd.DataFrame([{
            '–î–∞—Ç–∞': r[0].strftime('%Y-%m-%d'),
            '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞': r[2],
            '–û—Ü–µ–Ω–∫–∞': '‚òÖ' * int(r[3]),
            '–û—Ü–µ–Ω–∫–∞ (–±–∞–ª–ª—ã)': r[3],
            '–û—Ç–∑—ã–≤': r[1],
            '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å': sentiment_translation.get(s['label'].lower(), '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π')
        } for i, (r, s) in enumerate(zip(filtered_reviews, analysis['sentiments']))])
        
        st.dataframe(
            reviews_df[['–î–∞—Ç–∞', '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞', '–û—Ü–µ–Ω–∫–∞', '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', '–û—Ç–∑—ã–≤']],
            height=600,
            column_config={
                "–û—Ü–µ–Ω–∫–∞": st.column_config.TextColumn(width="small"),
                "–û—Ç–∑—ã–≤": st.column_config.TextColumn(width="large")
            }
        )
        
        csv = reviews_df[['–î–∞—Ç–∞', '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞', '–û—Ü–µ–Ω–∫–∞ (–±–∞–ª–ª—ã)', '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', '–û—Ç–∑—ã–≤']]
        csv = csv.to_csv(index=False).encode('utf-8')
        
        if st.download_button(
            label="üì• –°–∫–∞—á–∞—Ç—å –≤—Å–µ –æ—Ç–∑—ã–≤—ã",
            data=csv,
            file_name='–æ—Ç–∑—ã–≤—ã.csv',
            mime='text/csv',
            key='download_btn'
        ):
            st.session_state.analysis_data = analysis
            st.session_state.filtered_reviews = filtered_reviews
            st.experimental_rerun()
    
    if st.button("üîÑ –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", type="secondary"):
        st.session_state.clear()
        st.experimental_rerun()

def main():
    st.set_page_config(
        page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–∑—ã–≤–æ–≤", 
        layout="wide",
        menu_items={'About': "### –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–∑—ã–≤–æ–≤ v4.0"}
    )
    st.title("üì± –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–∑—ã–≤–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º URL –≤ —Å–µ—Å—Å–∏–∏
    col1, col2 = st.columns(2)
    with col1:
        gp_url = st.text_input(
            "–°—Å—ã–ª–∫–∞ Google Play", 
            value=st.session_state.get('gp_url', ''),
            key='gp_url_input'
        )
    with col2:
        ios_url = st.text_input(
            "–°—Å—ã–ª–∫–∞ App Store", 
            value=st.session_state.get('ios_url', ''),
            key='ios_url_input'
        )
    
    start_date = st.date_input("–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞", datetime.date(2024, 1, 1))
    end_date = st.date_input("–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞", datetime.date.today())
    
    if st.button("üöÄ –ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary"):
        st.session_state.gp_url = gp_url
        st.session_state.ios_url = ios_url
        
        with st.spinner("–°–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤..."):
            gp_revs, gp_rating = get_google_play_reviews(gp_url)
            ios_revs, ios_rating = get_app_store_reviews(ios_url)
            all_reviews = gp_revs + ios_revs
            
            if not all_reviews:
                st.error("–û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
                return
                
            start_dt = datetime.datetime.combine(start_date, datetime.time.min)
            end_dt = datetime.datetime.combine(end_date, datetime.time.max)
            filtered_reviews = filter_reviews_by_date(all_reviews, start_dt, end_dt)
            
            with st.spinner("–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞..."):
                analysis = analyze_reviews(filtered_reviews)
                analysis.update({
                    'gp_rating': gp_rating,
                    'ios_rating': ios_rating,
                    'platform_counts': {
                        'Google Play': sum(1 for r in filtered_reviews if r[2] == 'Google Play'),
                        'App Store': sum(1 for r in filtered_reviews if r[2] == 'App Store')
                    }
                })
            
            st.session_state.analysis_data = analysis
            st.session_state.filtered_reviews = filtered_reviews
            st.experimental_rerun()
    
    if 'analysis_data' in st.session_state and 'filtered_reviews' in st.session_state:
        display_analysis(st.session_state.analysis_data, st.session_state.filtered_reviews)

if __name__ == "__main__":
    main()
