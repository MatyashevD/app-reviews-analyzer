import datetime
import re
import spacy
import pandas as pd
import streamlit as st
import requests
import urllib.parse
from bs4 import BeautifulSoup
from google_play_scraper import app as gp_app, reviews as gp_reviews, Sort
from app_store_scraper import AppStore
from collections import Counter, defaultdict
from transformers import pipeline

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NLP –º–æ–¥–µ–ª–∏
def load_nlp_model():
    try:
        return spacy.load("ru_core_news_sm")
    except:
        spacy.cli.download("ru_core_news_sm")
        return spacy.load("ru_core_news_sm")

nlp = load_nlp_model()

@st.cache_resource(show_spinner="–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏...")
def load_sentiment_model():
    return pipeline(
        "text-classification", 
        model="cointegrated/rubert-tiny-sentiment-balanced",
        framework="pt",
        device=-1
    )

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API
GOOGLE_PLAY_COUNTRY = "ru"
APP_STORE_COUNTRY = "ru"
MAX_RESULTS = 5

def search_apps(query: str):
    """–ü–æ–∏—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
    results = {"google_play": [], "app_store": []}
    
    try:
        # –ü–æ–∏—Å–∫ –≤ Google Play
        gp_results = search(
            query,
            lang="ru",
            country=GOOGLE_PLAY_COUNTRY,
            n_hits=MAX_RESULTS
        )
        results["google_play"] = [{
            "id": r["appId"],
            "title": r["title"],
            "developer": r["developer"],
            "score": r["score"]
        } for r in gp_results]
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Google Play: {str(e)}")
    
    try:
        # –ü–æ–∏—Å–∫ –≤ App Store —á–µ—Ä–µ–∑ iTunes API
        itunes_response = requests.get(
            "https://itunes.apple.com/search",
            params={
                "term": query,
                "country": APP_STORE_COUNTRY,
                "media": "software",
                "limit": MAX_RESULTS
            }
        )
        ios_data = itunes_response.json()
        results["app_store"] = [{
            "id": r["trackId"],
            "title": r["trackName"],
            "developer": r["artistName"],
            "score": r["averageUserRating"]
        } for r in ios_data.get("results", [])]
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ App Store: {str(e)}")
    
    return results

def display_search_results(results: dict):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
    st.subheader("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")
    
    if not results["google_play"] and not results["app_store"]:
        st.warning("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # Google Play
    if results["google_play"]:
        st.markdown("### Google Play")
        for i, app in enumerate(results["google_play"], 1):
            with st.expander(f"{i}. {app['title']}"):
                st.write(f"**–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫:** {app['developer']}")
                st.write(f"**–†–µ–π—Ç–∏–Ω–≥:** {app['score']:.1f} ‚òÖ")
                if st.button(f"–í—ã–±—Ä–∞—Ç—å", key=f"gp_{app['id']}"):
                    st.session_state.selected_gp_app = app
    
    # App Store
    if results["app_store"]:
        st.markdown("### App Store")
        for i, app in enumerate(results["app_store"], 1):
            with st.expander(f"{i}. {app['title']}"):
                st.write(f"**–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫:** {app['developer']}")
                st.write(f"**–†–µ–π—Ç–∏–Ω–≥:** {app['score']:.1f} ‚òÖ")
                if st.button(f"–í—ã–±—Ä–∞—Ç—å", key=f"ios_{app['id']}"):
                    st.session_state.selected_ios_app = app

def get_app_store_rating(app_id: str) -> float:
    try:
        url = f"https://itunes.apple.com/ru/lookup?id={app_id}"
        response = requests.get(url, headers={
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        })
        data = response.json()
        return float(data['results'][0]['averageUserRating']) if data.get('results') else 0.0
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ App Store: {str(e)}")
        return 0.0

def get_google_play_reviews(app_name: str, lang: str = 'ru', country: str = 'ru', count: int = 100) -> tuple:
    app_id = search_google_play(app_name)
    if not app_id:
        return [], 0.0
    
    try:
        app_info = gp_app(app_id, lang=lang, country=country)
        rating = app_info.get('score', 0.0)
        
        result, _ = gp_reviews(
            app_id,
            lang=lang,
            country=country,
            count=count,
            sort=Sort.NEWEST
        )
        return [(r['at'], r['content'], 'Google Play', r['score']) for r in result], rating
    except:
        return [], 0.0

def get_app_store_reviews(app_name: str, country: str = 'ru', count: int = 100) -> tuple:
    app_id = search_app_store(app_name)
    if not app_id:
        return [], 0.0
    
    try:
        rating = get_app_store_rating(app_id)
        
        app = AppStore(country=country, app_id=app_id, app_name=app_name)
        app.review(how_many=count)
        
        return [(r['date'], r['review'], 'App Store', r['rating']) for r in app.reviews], rating
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ App Store: {str(e)}")
        return [], 0.0

def filter_reviews_by_date(reviews: list, start_date: datetime.datetime, end_date: datetime.datetime) -> list:
    return [r for r in reviews if start_date <= r[0] <= end_date]

def analyze_sentiments(reviews: list) -> list:
    try:
        sentiment_analyzer = load_sentiment_model()
        return [sentiment_analyzer(text[:512], truncation=True)[0] for _, text, _, _ in reviews]
    except:
        return [{'label': 'neutral', 'score': 0.5} for _ in reviews]

def extract_key_phrases(text: str) -> list:
    try:
        doc = nlp(text)
        phrases = []
        current_phrase = []
        
        for token in doc:
            if token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'VERB']:
                current_phrase.append(token.text)
                if len(current_phrase) == 4:
                    phrases.append(' '.join(current_phrase))
                    current_phrase = []
            else:
                if current_phrase:
                    phrases.append(' '.join(current_phrase))
                    current_phrase = []
        
        if current_phrase:
            phrases.append(' '.join(current_phrase))
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—Ä–∞–∑
        filtered_phrases = [
            phrase.strip().lower()
            for phrase in phrases 
            if 2 <= len(phrase.split()) <= 4
            and not any(c in phrase for c in ['@', '#', 'http'])
        ]
        
        return list(set(filtered_phrases))
    
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
        return []

def analyze_reviews(reviews: list) -> dict:
    analysis = {
        'sentiments': [],
        'key_phrases': Counter(),
        'platform_counts': Counter(),
        'examples': defaultdict(list),
        'gp_rating': 0.0,
        'ios_rating': 0.0
    }
    
    sentiments = analyze_sentiments(reviews)
    
    for idx, (date, text, platform, rating) in enumerate(reviews):
        analysis['sentiments'].append(sentiments[idx])
        analysis['platform_counts'][platform] += 1
        
        phrases = extract_key_phrases(text)
        for phrase in phrases:
            analysis['key_phrases'][phrase] += 1
            
            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ —Ñ—Ä–∞–∑—ã –≤ —Ç–µ–∫—Å—Ç–µ
            start_idx = text.lower().find(phrase)
            if start_idx != -1:
                # –í—ã—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —Ñ—Ä–∞–∑—ã
                start = max(0, start_idx - 30)
                end = min(len(text), start_idx + len(phrase) + 30)
                example = text[start:end].strip()
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞
                if start > 0:
                    example = "..." + example
                if end < len(text):
                    example += "..."
                    
                example = example.replace(phrase, f"**{phrase}**")
            else:
                example = text[:100] + "..."
            
            if len(analysis['examples'][phrase]) < 3:
                analysis['examples'][phrase].append(example)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ—Ä–∞–∑—ã —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏
    unique_phrases = []
    for phrase, count in analysis['key_phrases'].most_common():
        unique_examples = list({ex for ex in analysis['examples'][phrase]})
        if len(unique_examples) > 0:
            analysis['examples'][phrase] = unique_examples
            unique_phrases.append((phrase, count))
    
    analysis['key_phrases'] = Counter(dict(unique_phrases[:15]))
    
    return analysis

def display_analysis(analysis: dict, filtered_reviews: list):
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    st.session_state.analysis_data = analysis
    st.session_state.filtered_reviews = filtered_reviews
    
    tab1, tab2 = st.tabs(["–ê–Ω–∞–ª–∏—Ç–∏–∫–∞", "–í—Å–µ –æ—Ç–∑—ã–≤—ã"])
    
    with tab1:
        cols = st.columns(3)
        cols[0].metric("–í—Å–µ–≥–æ –æ—Ç–∑—ã–≤–æ–≤", len(filtered_reviews))
        cols[1].metric(
            "Google Play", 
            f"{analysis['platform_counts']['Google Play']} –æ—Ç–∑—ã–≤–æ–≤",
            f"‚òÖ {analysis['gp_rating']:.1f}" if analysis['gp_rating'] > 0 else ""
        )
        cols[2].metric(
            "App Store", 
            f"{analysis['platform_counts']['App Store']} –æ—Ç–∑—ã–≤–æ–≤",
            f"‚òÖ {analysis['ios_rating']:.1f}" if analysis['ios_rating'] > 0 else ""
        )
        
        st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        sentiment_counts = {
            '–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ': sum(1 for s in analysis['sentiments'] if s['label'].lower() == 'positive'),
            '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ': sum(1 for s in analysis['sentiments'] if s['label'].lower() == 'neutral'),
            '–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ': sum(1 for s in analysis['sentiments'] if s['label'].lower() == 'negative')
        }

        if sum(sentiment_counts.values()) > 0:
            sentiment_df = pd.DataFrame.from_dict(sentiment_counts, orient='index', columns=['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
            st.bar_chart(sentiment_df)
        else:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        
        st.subheader("üîë –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã (–¢–æ–ø-15)")
        if analysis['key_phrases']:
            top_phrases = analysis['key_phrases'].most_common(15)
            
            st.markdown("""
            <style>
                .phrase-box {
                    border: 1px solid #e6e6e6;
                    border-radius: 8px;
                    padding: 15px;
                    margin: 10px 0;
                    background: #f9f9f9;
                }
                .phrase-text {
                    font-weight: 600;
                    color: #2c3e50;
                    font-size: 16px;
                }
                .phrase-count {
                    color: #3498db;
                    font-size: 14px;
                }
                .phrase-example {
                    color: #7f8c8d;
                    font-size: 14px;
                    margin-top: 8px;
                }
            </style>
            """, unsafe_allow_html=True)
            
            for phrase, count in top_phrases:
                examples = analysis['examples'].get(phrase, [])[:2]
                examples_html = "<br>".join([f"‚Ä¢ {ex}" for ex in examples])
                
                st.markdown(f"""
                <div class="phrase-box">
                    <div class="phrase-text">
                        {phrase} 
                        <span class="phrase-count">({count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π)</span>
                    </div>
                    <div class="phrase-example">
                        –ü—Ä–∏–º–µ—Ä—ã:<br>
                        {examples_html if examples else "–ù–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤"}
                    </div>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
    
    with tab2:
        st.subheader("üìã –í—Å–µ –æ—Ç–∑—ã–≤—ã")
        sentiment_translation = {
            'positive': '–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π',
            'neutral': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π',
            'negative': '–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π'
        }
        
        reviews_df = pd.DataFrame([{
            '–î–∞—Ç–∞': r[0].strftime('%Y-%m-%d'),
            '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞': r[2],
            '–û—Ü–µ–Ω–∫–∞': '‚òÖ' * int(r[3]),
            '–û—Ü–µ–Ω–∫–∞ (–±–∞–ª–ª—ã)': r[3],
            '–û—Ç–∑—ã–≤': r[1],
            '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å': sentiment_translation.get(s['label'].lower(), '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π')
        } for i, (r, s) in enumerate(zip(filtered_reviews, analysis['sentiments']))])
        
        st.dataframe(
            reviews_df[['–î–∞—Ç–∞', '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞', '–û—Ü–µ–Ω–∫–∞', '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', '–û—Ç–∑—ã–≤']],
            height=600,
            column_config={
                "–û—Ü–µ–Ω–∫–∞": st.column_config.TextColumn(width="small"),
                "–û—Ç–∑—ã–≤": st.column_config.TextColumn(width="large")
            }
        )
        
        csv = reviews_df[['–î–∞—Ç–∞', '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞', '–û—Ü–µ–Ω–∫–∞ (–±–∞–ª–ª—ã)', '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', '–û—Ç–∑—ã–≤']]
        csv = csv.to_csv(index=False).encode('utf-8')
        
        if st.download_button(
            label="üì• –°–∫–∞—á–∞—Ç—å –≤—Å–µ –æ—Ç–∑—ã–≤—ã",
            data=csv,
            file_name='–æ—Ç–∑—ã–≤—ã.csv',
            mime='text/csv',
            key='download_btn'
        ):
            st.session_state.analysis_data = analysis
            st.session_state.filtered_reviews = filtered_reviews
            st.experimental_rerun()
    
    if st.button("üîÑ –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", type="secondary"):
        st.session_state.clear()
        st.experimental_rerun()

def main():
     st.set_page_config(
        page_title="–ü–æ–∏—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π",
        layout="wide",
        menu_items={'About': "### –ü–æ–∏—Å–∫ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π v2.0"}
    )
     st.title("üì≤ –ü–æ–∏—Å–∫ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π")
    
    # –ü–æ–∏—Å–∫–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
     search_query = st.text_input(
        "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:",
        placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: TikTok, –°–±–µ—Ä–ë–∞–Ω–∫",
        key="search_input"
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if 'search_results' not in st.session_state:
        st.session_state.search_results = None
    
    # –ö–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞
    if st.button("üîé –ù–∞–π—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è", type="primary"):
        if len(search_query) < 3:
            st.warning("–í–≤–µ–¥–∏—Ç–µ –º–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞")
        else:
            with st.spinner("–ò—â–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è..."):
                st.session_state.search_results = search_apps(search_query)
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if st.session_state.search_results:
        display_search_results(st.session_state.search_results)
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
    if 'selected_gp_app' in st.session_state:
        st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Google Play: {st.session_state.selected_gp_app['title']}")
    
    if 'selected_ios_app' in st.session_state:
        st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ App Store: {st.session_state.selected_ios_app['title']}")
    
    # –ö–Ω–æ–ø–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
    if 'selected_gp_app' in st.session_state or 'selected_ios_app' in st.session_state:
        if st.button("üöÄ –ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤", type="primary"):
            get_reviews()
            
    if reviews_gp or reviews_ios:
                filtered_reviews = reviews_gp + reviews_ios
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–∑—ã–≤–æ–≤ –ø–æ –¥–∞—Ç–∞–º
                start_datetime = datetime.datetime.combine(start_date, datetime.time.min)
                end_datetime = datetime.datetime.combine(end_date, datetime.time.max)
                filtered_reviews = filter_reviews_by_date(filtered_reviews, start_datetime, end_datetime)
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç–∑—ã–≤—ã
                analysis = analyze_reviews(filtered_reviews)
                
                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                display_analysis(analysis, filtered_reviews)
            else:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ—Ç–∑—ã–≤—ã.")

if __name__ == "__main__":
    main()
